---
title: "Un outil d'analyse exploratoire avec Tableau et R"
author: '[Simon Keith](Profil publichttps://fr.linkedin.com/in/simonkth), [Actinvision](http://www.actinvision.fr/)'
date: "16 mars 2016"
output:
  html_document:
    highlight: zenburn
    keep_md: yes
    theme: united
---
<br>  

# Introduction
### Vous avez dit analyse exploratoire ?
...  
<br>  

### Pourquoi Tableau est un bon candidat
...  
<br>  

### Prérequis
Tous des fichiers sont disponible dans ce [répertoire Github](https://github.com/simonkth/TableauR_ExploratoryAnalysis).  
Si vous souhaitez reproduire cet outil, assurez-vous de remplir les prérequis suivants avant de continuer :  

* avoir installé une version de Tableau Desktop supportant l'intégration avec R (8.1 ou supérieure)  
      + vous pouvez vous procurer une version d'essai à [cette adresse](http://get.tableau.com/fr-fr/partner-trial.html?partner=29294)  
* avoir installé R version 3.0.2 ou supérieure (disponible [ici](https://www.r-project.org/))  
* avoir ajouté R à votre variable d'environnement _path_ (par exemple, "_C:\\Program Files\\R\\R-3.0.2\\bin\\x64_")  
* avoir lancé Rserve en tâche d'arrière plan  
      + pour une configuration rapide et suffisante dans notre cas, téléchargez le contenu du [répertoire Github](https://github.com/simonkth/TableauR_ExploratoryAnalysis) et double-cliquez sur _Rserve.cmd_ dans le dossier _Rserve_ (ne fermez pas la fenêtre qui s'ouvre)  
      + pour une installation plus durable et plus flexible, suivez [ces instructions](http://kb.tableau.com/articles/knowledgebase/r-implementation-notes?lang=fr-fr)  
<br>  

# ...
...  
<br>  

# Jeu de données
### Origine et description
Le jeu de données que nous allons utiliser pour cette démonstration provient de la plateforme ouverte des [données publiques françaises](https://www.data.gouv.fr/fr/). Il contient un certain nombre d'indicateurs concernant l'insertion professionnelle des diplômés de Master en universités, fournis par le site de l'[enseignement supérieur français](www.enseignementsup-recherche.gouv.fr).  

Le jeu de données brut et sa documentation sont disponible [ici](https://www.data.gouv.fr/fr/datasets/insertion-professionnelle-des-diplomes-de-master-en-universites-et-etablissements-assimil-0/).  
<br>  

### Nettoyage et préparation avec R
Si le travail de préparation des données ne vous intéresse pas et que vous souhaitez directement attaquer les manipulations dans Tableau, vous pouvez passer cette section.  

Sinon, n'oubliez pas de configurer au préalable votre répertoire de travail avec la fonction `setwd`.  

Nous commençons par télécharger les données, puis nous réglons les problèmes de qualité des données. Nous supprimons ensuite les cas où le nombre de réponses est inférieur à 30, ainsi que ceux où le taux de réponse est inférieur à 30%. Nous sélection également les colonnes qui nous intéressent. Enfin, nous exportons un fichier _.csv_ pour Tableau et nous affichons un échantillon des données.  
```{r dl_clean, cache=TRUE, message=FALSE}
# load packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(downloader, data.table, dplyr)

# download and load the data (Windows setup)
if(!file.exists("./data/insertion_raw.csv")) {
      if(!file.exists("./data")) {dir.create("./data")}
      dataUrl <- paste0("https://data.enseignementsup-recherche.gouv.fr/explore/dataset/", 
                        "fr-esr-insertion_professionnelle-master/download?format=csv")
      download(dataUrl, dest="./data/insertion_raw.csv", mode="wb")
} else message("The dataset had previously been downloaded.")

# read data with fread(), with list of strings to ignore
insertion <- fread("./data/insertion_raw.csv", sep=";", encoding="UTF-8", 
                  na.strings=c("NA", "ns", "nd", "fe", ".", paste0(1, "\U00A0", 710), ""))

# remove data if sample is too small (nombre_de_reponses < 30) 
# or if the response rate is too low (taux_de_reponse < 30)
# also remove fields that we don't want to keep in Tableau
insertion <- insertion %>% 
      filter(nombre_de_reponses >= 30, taux_de_reponse >= 30, 
             numero_de_l_etablissement != "UNIV") %>%
      select(-c(numero_de_l_etablissement, code_de_l_academie, code_du_domaine, 
                code_de_la_discipline, remarque, cle_etab, cle_disc))
      
# export data in csv for Tableau
# note: we remove R "NAs" and replace with empty cells since Tableau doesn't handle them
insertion_noNa <- insertion
insertion_noNa[is.na(insertion_noNa)] <- ""
write.csv(insertion_noNa, "./data/insertion_Tableau.csv", row.names=FALSE)
remove(insertion_noNa)

# show sample
str(insertion)
```
<br>  

# Développement des outils d'analyse
### ...
...  
<br>  

### Nuage de points et densitées marginales
L'un de mes premiers réflexes lorsque j'explore un nouveau jeu de données est de rechercher des relation entre les différentes variables. Pour les variables quantitatives, le nuage de point est un incontournable. Sur ce type de graphique, j'ai également tendance à utiliser la couleur pour comparer les différents niveaux d'une variable qualitative (ou dimension).  

Le problème avec les nuages de points, c'est qu'ils ont tendance à devenir rapidement illisibles lorsqu'il y a beaucoup d'éléments à afficher. Il est donc intéressant d'enrichir ces vues. On peut ainsi y ajouter différents éléments : une courbe de tendance, le résultat d'un test statistique, ou encore les densités marginales des nos variables...  

Ci-dessous une petite démonstration rapide en R avec le package _ggplot2_. J'ai ajouté une courbe de régression [LOESS](https://en.wikipedia.org/wiki/Local_regression), le résultat d'un [test de corrélation de Pearson](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient) ainsi que les [distributions marginales](https://en.wikipedia.org/wiki/Marginal_distribution) déclinées en couleur sur les différents domaines d'études proposés par nos universités. C'est une démonstration rapide, je n'ai donc pas pris la peine d'afficher la légende. Vous remarquerez aussi que cela demande beaucoup de code, et que l'alignement des différents éléments reste assez approximatif.  
```{r scatterMargins, warning=FALSE, fig.height=6, fig.width=9, fig.align='center'}
# load packages for graphics
pacman::p_load(ggplot2, gridExtra)

# set variables
graphData <- data.frame(
      axisX=insertion$femmes,
      axisY=insertion$salaire_net_median_des_emplois_a_temps_plein, 
      colDim=insertion$domaine
      )
graphData <- graphData[complete.cases(graphData),]
axisNames <- c("Pourcentage de femmes", "Salaire net médian")

# helper function for graphic themes
myTheme <- function(...) theme(legend.position="none", 
                               panel.background=element_blank(), 
                               panel.grid.major=element_blank(), 
                               panel.grid.minor=element_blank(), 
                               panel.margin=unit(0, "null"), 
                               axis.ticks=element_blank(), 
                               axis.text.x=element_blank(), 
                               axis.text.y=element_blank(), 
                               axis.title.x=element_blank(), 
                               axis.title.y=element_blank(), 
                               panel.border=element_rect(color=NA), ...)

# plotting Pearson's correlation test
corTest <- with(graphData, cor.test(axisX, axisY, method="pearson"))
corText <- paste0("Pearson's r: ", formatC(corTest$estimate, digits=4, format="f"), 
                  "\np value: ", formatC(corTest$p.value, digits=4, format="e"))
gText <- ggplot() + 
  annotate("text", x=0, y=0, size=4, label=corText) + 
  theme_bw() + myTheme()

# scatterplot with LOESS smooth line
g1 <- ggplot(graphData, aes(x=axisX, y=axisY, colour=factor(colDim))) +
      geom_point(alpha=0.4, size=1.5) + 
      geom_smooth(aes(x=axisX, y=axisY), 
                  inherit.aes=FALSE, method="loess") +
      scale_x_continuous(expand=c(0.01, 0.01)) +
      scale_y_continuous(expand=c(0.01, 0.01)) +
      theme_bw() + xlab(axisNames[1]) + ylab(axisNames[2]) +
      theme(legend.position="none", plot.margin=unit(c(1, 1, 1, 1), "points"))

# x marginal density
g2 <- ggplot(graphData, aes(x=axisX, colour=factor(colDim), fill=factor(colDim))) + 
  geom_density(alpha=0.4) + 
  scale_x_continuous(breaks=NULL, expand=c(0.01, 0.01)) +
  scale_y_continuous(breaks=NULL, expand=c(0, 0)) +
  theme_bw() +
  myTheme(plot.margin=unit(c(0, 0, 0, 3), "lines")) 

# y marginal density
g3 <- ggplot(graphData, aes(x=axisY, colour=factor(colDim), fill=factor(colDim))) + 
  geom_density(alpha=0.4) + 
  coord_flip()  + 
  scale_x_continuous(labels=NULL, breaks=NULL, expand=c(0.01, 0.01)) +
  scale_y_continuous(labels=NULL, breaks=NULL, expand=c(0, 0)) +
  theme_bw() +
  myTheme(plot.margin=unit(c(0, 0, 2.1, 0), "lines"))

# arrange plots
remove(graphData, axisNames)
grid.arrange(arrangeGrob(g2, gText, ncol=2, widths=c(3, 1)), 
             arrangeGrob(g1, g3, ncol=2, widths=c(3, 1)), 
             heights=c(1, 3))
```
<br>  
Bien entendu ce code pourrait être largement amélioré (ajout de la légende, alignement dynamique des différents éléments, etc.) mais vous avez compris le problème : c'est difficile à maintenir, et surtout cela manque cruellement d’interactivité. Je peux changer mes variables, mais pour cela je dois modifier puis relancer mon code. De plus, je ne suis pas sûr que l'alignement de mes graphiques restera bon. Je n'ai pas non plus la possibilité d'ajouter des infobulles ni de filtrer mes données... Bref, et si l'on essayait de porter tout cela dans Tableau ?  
<br>  

Vous trouverez le classeur Tableau dans le [répertoire Github](https://github.com/simonkth/TableauR_ExploratoryAnalysis) (_TableauR_ExploratoryAnalysis_FR.twb_). Je ne vais pas détailler tous les champs calculés, aussi je vous conseille de travailler avec deux fenêtres de Tableau. Dans la première, ouvrez mon classeur et jetez y un coup d’œil de temps en temps pour voir comment je m'y suis pris. Dans la deuxième, ouvrez un classeur vierge et recommencez à partir de zéro.  

La première étape est de se connecter aux données (fichier _insertion_Tableau.csv_). N'hésitez pas à renommer les champs et à formater correctement les mesures, comme je l'ai fait. Puis nous passons au premier élément, le nuage de points.  

D'abord, n'oublier pas de désactiver l'agrégation dans _Analyse_ $\rightarrow$ _Agréger les mesures_. Ensuite, le premier réflexe est de dynamiser notre vue en créant un certain nombre de paramètres, ainsi que les champs paramétrables correspondants. Faites _clique-droit_ $\rightarrow$ _modifier_ pour comprendre comment ils sont construits. Pour le nuage de points, nous avons donc :  

* le paramètre __Abscisse__ qui commande le champ __X__  
* le paramètre __Ordonnée__ qui commande le champ __Y__  
* les paramètres __Niveaux__ et __Niveaux maximum__ qui commandent les champs __Niveaux pour couleur__ et __Couleur__  

Grâce aux deux premiers paramètres, je peux choisir les mesures que je souhaite placer en abscisse et en ordonnée. Quelques précisions s'imposent pour le dernier point. Grâce à __Niveaux__, je peux choisir une dimension pour déterminer la couleur des points (via le champ __Niveaux pour couleur__). Cependant je ne contrôle pas le nombre de niveaux que contient cette dimension ! Par sécurité, je créé un nouveau couple paramètre / champ calculé (__Niveaux maximum__ et __Couleur__) qui va me permettre de n'afficher des couleurs que si le nombre de niveaux ne dépasse pas un certain seuil. C'est donc le champ __Couleur__ que je place sur mon repère des couleurs. En revanche, je peux utiliser le champ __Niveaux pour couleur__ pour filtrer ma dimension. Ainsi, bien qu'il y ait 28 niveaux pour la dimension __Académie__, si je la sélectionne puis que je filtre pour ne garder que 6 niveaux (et que __Niveaux maximum__ est fixé à 6), les académies que j'ai sélectionné vont bel et bien s'afficher en couleur. En revanche si j'ajoute une académie de trop à ma sélection, Tableau repasse sur une couleur unique.  

Les paramètres __Abscisse__ et __Ordonnée__ sont respectivement placés en colonne et en ligne pour faire office de titre d'axe. Je filtre également mes champs __X__ et __Y__ pour exclure les cas où les valeur sont manquantes.  

![Nuage de points dynamique dans Tableau](figures/nuage_de_points.png)

